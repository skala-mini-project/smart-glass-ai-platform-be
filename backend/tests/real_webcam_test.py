# ì‹¤ì œ ì›¹ìº  í†µí•© í…ŒìŠ¤íŠ¸
import cv2
import numpy as np
from datetime import datetime
import json
import asyncio
import sys
import os

# ë°±ì—”ë“œ ëª¨ë“ˆ import
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

from vision_service.core.detector import VisionDetector
from rag_service.services.rag_service import RAGService
from vision_service.services.ocr_service import OCRService

class RealWebcamTest:
    """ì‹¤ì œ ì›¹ìº ì„ ì‚¬ìš©í•œ í†µí•© í…ŒìŠ¤íŠ¸"""
    
    def __init__(self):
        self.vision_detector = VisionDetector()
        self.rag_service = RAGService()
        self.ocr_service = OCRService()
        self.cap = None
        self.frame_count = 0
        self.detection_history = []
    
    def initialize_webcam(self):
        """ì›¹ìº  ì´ˆê¸°í™”"""
        print("ğŸ“¹ ì›¹ìº  ì´ˆê¸°í™” ì¤‘...")
        self.cap = cv2.VideoCapture(0)
        
        if not self.cap.isOpened():
            print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return False
        
        # ì›¹ìº  ì„¤ì •
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        self.cap.set(cv2.CAP_PROP_FPS, 30)
        
        print("âœ… ì›¹ìº  ì´ˆê¸°í™” ì™„ë£Œ!")
        return True
    
    def process_frame(self, frame):
        """í”„ë ˆì„ ì²˜ë¦¬"""
        self.frame_count += 1
        
        # 1. ê°ì²´ íƒì§€
        detection_result = self.vision_detector.detect_objects(frame)
        
        # 2. OCR í…ìŠ¤íŠ¸ ì¶”ì¶œ
        ocr_result = self.ocr_service.extract_text(frame)
        
        # 3. ê²°ê³¼ ì‹œê°í™”
        processed_frame = self.visualize_results(frame, detection_result, ocr_result)
        
        # 4. íˆìŠ¤í† ë¦¬ ì €ì¥
        frame_info = {
            "frame_id": self.frame_count,
            "timestamp": datetime.now().isoformat(),
            "detections": len(detection_result['objects']),
            "texts": len(ocr_result['texts']),
            "objects": detection_result['objects'],
            "texts": ocr_result['texts']
        }
        self.detection_history.append(frame_info)
        
        return processed_frame, detection_result, ocr_result
    
    def visualize_results(self, frame, detection_result, ocr_result):
        """ê²°ê³¼ ì‹œê°í™”"""
        processed_frame = frame.copy()
        
        # ê°ì²´ íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
        for obj in detection_result['objects']:
            bbox = obj['bbox']
            x, y, w, h = bbox['x'], bbox['y'], bbox['width'], bbox['height']
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            cv2.rectangle(processed_frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
            
            # ë¼ë²¨ê³¼ ì‹ ë¢°ë„ í‘œì‹œ
            label = f"{obj['label']}: {obj['confidence']:.2f}"
            cv2.putText(processed_frame, label, (x, y - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
        
        # OCR í…ìŠ¤íŠ¸ ê²°ê³¼ ê·¸ë¦¬ê¸°
        for text_info in ocr_result['texts']:
            bbox = text_info['bbox']
            x, y, w, h = bbox[0], bbox[1], bbox[2], bbox[3]
            
            # í…ìŠ¤íŠ¸ ì˜ì—­ ê·¸ë¦¬ê¸°
            cv2.rectangle(processed_frame, (x, y), (x + w, y + h), (255, 0, 0), 2)
            
            # í…ìŠ¤íŠ¸ í‘œì‹œ
            cv2.putText(processed_frame, text_info['text'], (x, y - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)
        
        # í”„ë ˆì„ ì •ë³´ í‘œì‹œ
        info_text = f"Frame: {self.frame_count} | Objects: {len(detection_result['objects'])} | Texts: {len(ocr_result['texts'])}"
        cv2.putText(processed_frame, info_text, (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        
        return processed_frame
    
    async def run_realtime_test(self, duration_seconds=30):
        """ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        if not self.initialize_webcam():
            return
        
        print(f"ğŸš€ ì‹¤ì‹œê°„ í…ŒìŠ¤íŠ¸ ì‹œì‘! ({duration_seconds}ì´ˆê°„ ì‹¤í–‰)")
        print("ğŸ“ 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.")
        print("=" * 50)
        
        start_time = datetime.now()
        
        try:
            while True:
                # í”„ë ˆì„ ì½ê¸°
                ret, frame = self.cap.read()
                if not ret:
                    print("âŒ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
                    break
                
                # í”„ë ˆì„ ì²˜ë¦¬
                processed_frame, detection_result, ocr_result = self.process_frame(frame)
                
                # í™”ë©´ì— í‘œì‹œ
                cv2.imshow('Real-time Vision AI Test', processed_frame)
                
                # í‚¤ ì…ë ¥ í™•ì¸
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("ğŸ›‘ ì‚¬ìš©ìê°€ ì¢…ë£Œë¥¼ ìš”ì²­í–ˆìŠµë‹ˆë‹¤.")
                    break
                
                # ì‹œê°„ ì²´í¬
                elapsed = (datetime.now() - start_time).total_seconds()
                if elapsed >= duration_seconds:
                    print(f"â° {duration_seconds}ì´ˆê°€ ì§€ë‚˜ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                    break
                
                # ì£¼ê¸°ì ìœ¼ë¡œ ê²°ê³¼ ì¶œë ¥
                if self.frame_count % 30 == 0:  # 30í”„ë ˆì„ë§ˆë‹¤
                    print(f"ğŸ“Š í”„ë ˆì„ {self.frame_count}: {len(detection_result['objects'])}ê°œ ê°ì²´, {len(ocr_result['texts'])}ê°œ í…ìŠ¤íŠ¸")
        
        except KeyboardInterrupt:
            print("\nğŸ›‘ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        
        finally:
            self.cleanup()
            self.save_results()
    
    def cleanup(self):
        """ì •ë¦¬ ì‘ì—…"""
        if self.cap:
            self.cap.release()
        cv2.destroyAllWindows()
        print("âœ… ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
    
    def save_results(self):
        """ê²°ê³¼ ì €ì¥"""
        results = {
            "test_type": "real_webcam_test",
            "timestamp": datetime.now().isoformat(),
            "total_frames": self.frame_count,
            "detection_history": self.detection_history,
            "summary": {
                "total_objects_detected": sum(len(frame['objects']) for frame in self.detection_history),
                "total_texts_extracted": sum(len(frame['texts']) for frame in self.detection_history),
                "average_objects_per_frame": sum(len(frame['objects']) for frame in self.detection_history) / max(self.frame_count, 1),
                "average_texts_per_frame": sum(len(frame['texts']) for frame in self.detection_history) / max(self.frame_count, 1)
            }
        }
        
        with open("real_webcam_test_results.json", "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print("ğŸ“„ ê²°ê³¼ íŒŒì¼ ì €ì¥: real_webcam_test_results.json")
        print(f"ğŸ“Š ì´ {self.frame_count}í”„ë ˆì„ ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ¯ í‰ê·  {results['summary']['average_objects_per_frame']:.2f}ê°œ ê°ì²´/í”„ë ˆì„")
        print(f"ğŸ“ í‰ê·  {results['summary']['average_texts_per_frame']:.2f}ê°œ í…ìŠ¤íŠ¸/í”„ë ˆì„")

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    tester = RealWebcamTest()
    await tester.run_realtime_test(duration_seconds=30)

if __name__ == "__main__":
    asyncio.run(main())
